{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import string\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "c9EhLJN_H6jC",
        "outputId": "06b4c276-27d8-4e89-f279-ebef1081f184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Part 1: Training and Saving the Model ---\n",
            "Loaded 227300 words from '/content/drive/My Drive/HMan/words.txt'.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3960893106.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2-3960893106.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, epochs, lr, device)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, maximize, foreach, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Register polyfill functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolyfills\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;31m# usort: skip # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/polyfills/loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"sys\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0;31m POLYFILLED_MODULES: Tuple[\"ModuleType\", ...] = tuple(\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{submodule}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolyfills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPOLYFILLED_MODULE_NAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/polyfills/loader.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m POLYFILLED_MODULES: Tuple[\"ModuleType\", ...] = tuple(\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{submodule}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolyfills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPOLYFILLED_MODULE_NAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/polyfills/builtins.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0msubstitute_in_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_constant_fold_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(traceable_fn)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Duplicate polyfilled object {original_fn}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mrule_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVariableTracker\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_torch_obj_rule_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrule_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mget_torch_obj_rule_map\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2873\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\".py#\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_module_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36mload_object\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2904\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Invalid obj name {name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_obj_from_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m_load_obj_from_str\u001b[0;34m(fully_qualified_name)\u001b[0m\n\u001b[1;32m   2888\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_obj_from_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfully_qualified_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2890\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_higher_order_ops/map.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDispatchKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuspend_functionalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maot_autograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAOTConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_joint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m from torch._higher_order_ops.utils import (\n\u001b[1;32m      8\u001b[0m     \u001b[0m_has_potential_branch_input_alias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m from ._aot_autograd.autograd_cache import (  # noqa: F401\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mAOTAutogradCache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mautograd_cache_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/autograd_cache.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m from .runtime_wrappers import (\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mAOTDispatchAutograd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mAOTDispatchSubclassWrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(\"--- Part 1: Training and Saving the Model ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURATION AND VOCABULARY\n",
        "# ==============================================================================\n",
        "MAX_LEN = 35\n",
        "HIDDEN_SIZE = 128\n",
        "NHEAD = 4\n",
        "NUM_LAYERS = 4\n",
        "GAME_STATE_SIZE = 27  # 1 for lives_remaining + 26 for one-hot incorrect guesses\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3  # Increase for better performance with a larger wordlist\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "MODEL_SAVE_PATH = 'character_bert_hangman_final.pth'\n",
        "WORDLIST_PATH = 'words.txt' # <-- Make sure this file exists\n",
        "\n",
        "# Define character vocabulary\n",
        "VOCAB = {'[PAD]': 0, '[MASK]': 1, **{char: i+2 for i, char in enumerate(string.ascii_lowercase)}}\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. MODEL AND DATASET DEFINITION\n",
        "# ==============================================================================\n",
        "\n",
        "class CharacterBERT(nn.Module):\n",
        "    \"\"\"The custom Transformer model for Hangman.\"\"\"\n",
        "    def __init__(self, vocab_size, max_len, hidden_size, nhead, num_layers, game_state_size):\n",
        "        super().__init__()\n",
        "        self.char_embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.position_embedding = nn.Embedding(max_len, hidden_size)\n",
        "        self.game_state_encoder = nn.Linear(game_state_size, hidden_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.mlm_head = nn.Linear(hidden_size, vocab_size)\n",
        "        self.register_buffer('positions', torch.arange(max_len))\n",
        "\n",
        "    def forward(self, input_ids, game_state_vector):\n",
        "        seq_len = input_ids.size(1)\n",
        "        x = self.char_embedding(input_ids) + self.position_embedding(self.positions[:seq_len])\n",
        "        x = x + self.game_state_encoder(game_state_vector).unsqueeze(1)\n",
        "        logits = self.mlm_head(self.transformer_encoder(x))\n",
        "        return logits\n",
        "\n",
        "class HangmanDataset(Dataset):\n",
        "    \"\"\"Generates Hangman game states for training.\"\"\"\n",
        "    def __init__(self, word_list, max_len):\n",
        "        self.word_list = [w.lower() for w in word_list if len(w) <= max_len and w.isalpha()]\n",
        "        self.max_len = max_len\n",
        "        self.alphabet = string.ascii_lowercase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word_list) * 20  # Generate 20 variations per word per epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word = random.choice(self.word_list)\n",
        "        unique_letters = list(set(word))\n",
        "\n",
        "        # Simulate guesses\n",
        "        num_to_reveal = random.randint(0, max(0, len(unique_letters) - 1))\n",
        "        correct_guesses = set(random.sample(unique_letters, num_to_reveal))\n",
        "\n",
        "        # *** LOGIC CHANGE: incorrect guesses are from letters NOT in the word ***\n",
        "        possible_incorrect = list(set(self.alphabet) - set(unique_letters))\n",
        "        num_incorrect = random.randint(0, 5)\n",
        "        incorrect_guesses = set(random.sample(possible_incorrect, num_incorrect))\n",
        "\n",
        "        # Create input pattern (shows correct guesses) and labels (shows missing chars)\n",
        "        input_pattern = [VOCAB[c] if c in correct_guesses else VOCAB['[MASK]'] for c in word]\n",
        "        labels = [VOCAB[c] if c not in correct_guesses else -100 for c in word]\n",
        "\n",
        "        # Pad sequences\n",
        "        padding_len = self.max_len - len(word)\n",
        "        input_ids = input_pattern + [VOCAB['[PAD]']] * padding_len\n",
        "        labels = labels + [-100] * padding_len\n",
        "\n",
        "        # *** LOGIC CHANGE: game_state_vector only encodes INCORRECT guesses ***\n",
        "        lives_remaining = 6 - len(incorrect_guesses)\n",
        "        incorrect_mask = [1.0 if c in incorrect_guesses else 0.0 for c in self.alphabet]\n",
        "        game_state_vector = [lives_remaining / 6.0] + incorrect_mask\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(labels, dtype=torch.long),\n",
        "            'game_state_vector': torch.tensor(game_state_vector, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. TRAINING LOOP\n",
        "# ==============================================================================\n",
        "\n",
        "from tqdm import tqdm  # Ensure tqdm is imported\n",
        "import torch.nn as nn  # If not already imported\n",
        "\n",
        "def train(model, dataloader, epochs, lr, device):\n",
        "    \"\"\"Main training loop with conditional logit masking and per-batch tracking.\"\"\"\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    print(f\"Starting training on {device} for {epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Wrap dataloader in tqdm for batch-level progress\n",
        "        batch_iterator = tqdm(dataloader, desc=\"Training Batches\", leave=False)\n",
        "\n",
        "        for batch_idx, batch in enumerate(batch_iterator):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            game_state_vector = batch['game_state_vector'].to(device)\n",
        "\n",
        "            logits = model(input_ids, game_state_vector)\n",
        "\n",
        "            # Mask logits using only INCORRECT guesses\n",
        "            incorrect_guesses_mask = game_state_vector[:, 1:]\n",
        "            logit_mask = torch.zeros(logits.size(0), VOCAB_SIZE, device=device)\n",
        "            logit_mask[:, 2:] = incorrect_guesses_mask * -1e9  # large negative value\n",
        "            masked_logits = logits + logit_mask.unsqueeze(1)\n",
        "\n",
        "            loss = criterion(masked_logits.view(-1, VOCAB_SIZE), labels.view(-1))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update tqdm description with current batch loss\n",
        "            batch_iterator.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(f\"\\n--- Training Complete. Model saved to '{MODEL_SAVE_PATH}' ---\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. EXECUTION\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        with open(WORDLIST_PATH, 'r') as f:\n",
        "            word_list = [line.strip() for line in f]\n",
        "        print(f\"Loaded {len(word_list)} words from '{WORDLIST_PATH}'.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: '{WORDLIST_PATH}' not found. Please create it.\")\n",
        "        exit()\n",
        "\n",
        "    # Initialize model and data\n",
        "    model = CharacterBERT(VOCAB_SIZE, MAX_LEN, HIDDEN_SIZE, NHEAD, NUM_LAYERS, GAME_STATE_SIZE)\n",
        "    dataset = HangmanDataset(word_list, MAX_LEN)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train the model\n",
        "    train(model, dataloader, epochs=EPOCHS, lr=LEARNING_RATE, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Rj-7OsomTN",
        "outputId": "7762cf10-6d02-40dc-ba90-2c6e61c3307e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and Dataset classes defined.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Model and Dataset Classes\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. MODEL DEFINITION\n",
        "# ==============================================================================\n",
        "class CharacterBERT(nn.Module):\n",
        "    \"\"\"The custom Transformer model for Hangman.\"\"\"\n",
        "    def __init__(self, vocab_size, max_len, hidden_size, nhead, num_layers, game_state_size):\n",
        "        super().__init__()\n",
        "        self.char_embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.position_embedding = nn.Embedding(max_len, hidden_size)\n",
        "        self.game_state_encoder = nn.Linear(game_state_size, hidden_size)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=nhead, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.mlm_head = nn.Linear(hidden_size, vocab_size)\n",
        "        self.register_buffer('positions', torch.arange(max_len))\n",
        "\n",
        "    def forward(self, input_ids, game_state_vector):\n",
        "        seq_len = input_ids.size(1)\n",
        "        x = self.char_embedding(input_ids) + self.position_embedding(self.positions[:seq_len])\n",
        "        x = x + self.game_state_encoder(game_state_vector).unsqueeze(1)\n",
        "        logits = self.mlm_head(self.transformer_encoder(x))\n",
        "        return logits\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DATASET DEFINITION\n",
        "# ==============================================================================\n",
        "class HangmanDataset(Dataset):\n",
        "    \"\"\"Generates Hangman game states for training.\"\"\"\n",
        "    def __init__(self, word_list, max_len):\n",
        "        self.word_list = [w.lower() for w in word_list if len(w) <= max_len and w.isalpha()]\n",
        "        self.max_len = max_len\n",
        "        self.alphabet = string.ascii_lowercase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word_list) * 20  # Generate 20 variations per word per epoch\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        word = random.choice(self.word_list)\n",
        "        unique_letters = list(set(word))\n",
        "\n",
        "        num_to_reveal = random.randint(0, max(0, len(unique_letters) - 1))\n",
        "        correct_guesses = set(random.sample(unique_letters, num_to_reveal))\n",
        "\n",
        "        possible_incorrect = list(set(self.alphabet) - set(unique_letters))\n",
        "        num_incorrect = random.randint(0, 5)\n",
        "        incorrect_guesses = set(random.sample(possible_incorrect, num_incorrect))\n",
        "\n",
        "        input_pattern = [VOCAB[c] if c in correct_guesses else VOCAB['[MASK]'] for c in word]\n",
        "        labels = [VOCAB[c] if c not in correct_guesses else -100 for c in word]\n",
        "\n",
        "        padding_len = self.max_len - len(word)\n",
        "        input_ids = input_pattern + [VOCAB['[PAD]']] * padding_len\n",
        "        labels = labels + [-100] * padding_len\n",
        "\n",
        "        lives_remaining = 6 - len(incorrect_guesses)\n",
        "        incorrect_mask = [1.0 if c in incorrect_guesses else 0.0 for c in self.alphabet]\n",
        "        game_state_vector = [lives_remaining / 6.0] + incorrect_mask\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "            'labels': torch.tensor(labels, dtype=torch.long),\n",
        "            'game_state_vector': torch.tensor(game_state_vector, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "print(\"Model and Dataset classes defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32iE2WxBo7wt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
